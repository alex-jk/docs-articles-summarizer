{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Lenovo Thinkpad\n",
      "[nltk_data]     T430\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Lenovo Thinkpad\n",
      "[nltk_data]     T430\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Lenovo Thinkpad\n",
      "[nltk_data]     T430\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Lenovo Thinkpad\n",
      "[nltk_data]     T430\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Lenovo Thinkpad\n",
      "[nltk_data]     T430\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-12-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "loading file vocab.json from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo Thinkpad T430\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = utils.load_model(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to summarize in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to detect valid summary part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.is_in_enchant_dict(\"antipsychotic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archswindler\n"
     ]
    }
   ],
   "source": [
    "# List of valid English words for reference\n",
    "valid_words = set(nltk.corpus.words.words())\n",
    "\n",
    "# List of valid English words for reference\n",
    "valid_words = set(nltk.corpus.words.words())\n",
    "\n",
    "domain_specific_words = ['lamotrigine', 'antidepressant', 'placebo', 'monotherapy']\n",
    "valid_words.update(domain_specific_words)\n",
    "\n",
    "print(list(valid_words)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check NLTK pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lamotrigine', 'NN'), ('evaluated', 'VBD')]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['lamotrigine', 'evaluated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'also known is its ability to improve social and occupational functioning of patients who are not taking it if they do not feel well '"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check expland contractions\n",
    "check_text = \"also known is its ability to improve social and occupational functioning of patients who are not taking it if they don't feel well \"\n",
    "\n",
    "utils.expand_contractions(check_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- lamotrigine was evaluated for its antidepressant efficacy and safety\n",
      "\n",
      "----- ['lamotrigine', 'was', 'evaluated', 'for', 'its', 'antidepressant', 'efficacy', 'and', 'safety']\n",
      "\n",
      "----- [('lamotrigine', 'NN'), ('was', 'VBD'), ('evaluated', 'VBN'), ('for', 'IN'), ('its', 'PRP$'), ('antidepressant', 'JJ'), ('efficacy', 'NN'), ('and', 'CC'), ('safety', 'NN')]\n",
      "\n",
      " Cleaned tokens: ['lamotrigine', 'was', 'evaluated', 'for', 'its', 'antidepressant', 'efficacy', 'and', 'safety']\n"
     ]
    }
   ],
   "source": [
    "check_sentence = \"lamotrigine was evaluated for its antidepressant efficacy and safety\"\n",
    "print(f\"\\n----- {check_sentence}\")\n",
    "\n",
    "tokens = nltk.word_tokenize(check_sentence)\n",
    "print(f\"\\n----- {tokens}\")\n",
    "\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(f\"\\n----- {pos_tags}\")\n",
    "\n",
    "cleaned_tokens = []\n",
    "for token, pos_tag in pos_tags:\n",
    "    # Check if the lemmatized form of the token is valid\n",
    "    if utils.is_valid_word(valid_words, token, pos_tag):\n",
    "        cleaned_tokens.append(token)\n",
    "    else:\n",
    "        # Once gibberish or non-valid words appear, stop processing\n",
    "        break\n",
    "print(f\"\\n Cleaned tokens: {cleaned_tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detect valid words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Len dataset for model: 177\n",
      "\n",
      "Index(['word', 'valid_label', 'contains_number', 'num_dashes', 'num_vowels',\n",
      "       'contains_non_alphanum', 'contains_ine', 'lemma',\n",
      "       'is_real_word_enchant', 'num_characters', 'starts_with_letter',\n",
      "       'ends_with_letter', 'contains_medical_term'],\n",
      "      dtype='object')\n",
      "\n",
      "----- 0           ((versiune, NN)\n",
      "1           (2001–2005, CD)\n",
      "2                 (25-, JJ)\n",
      "3           (31absence, CD)\n",
      "4               (50-mg, JJ)\n",
      "5                 (50s, CD)\n",
      "6                (5th, NNS)\n",
      "7                   (â, NN)\n",
      "8           (adjuctive, JJ)\n",
      "9                 (al., NN)\n",
      "10                (am:, NN)\n",
      "11           (american, JJ)\n",
      "12              (andor, NN)\n",
      "13         (anecyolypi, NN)\n",
      "14    (antipsychotics, NNS)\n",
      "Name: word, dtype: object\n",
      "\n",
      "\n",
      "               word  valid_label  contains_number  num_dashes  num_vowels  \\\n",
      "0         (versiune            0                0           0           4   \n",
      "1         2001–2005            0                1           0           0   \n",
      "2               25-            0                1           1           0   \n",
      "3         31absence            0                1           0           3   \n",
      "4             50-mg            1                1           1           0   \n",
      "5               50s            0                1           0           0   \n",
      "6               5th            0                1           0           0   \n",
      "7                 â            0                0           0           0   \n",
      "8         adjuctive            0                0           0           4   \n",
      "9               al.            1                0           0           1   \n",
      "10              am:            0                0           0           1   \n",
      "11         american            1                0           0           4   \n",
      "12            andor            0                0           0           2   \n",
      "13       anecyolypi            0                0           0           4   \n",
      "14   antipsychotics            1                0           0           4   \n",
      "15  anxiolytic-like            1                0           1           6   \n",
      "16      âœeverybody            0                0           0           3   \n",
      "17        âœplanned            0                0           0           2   \n",
      "18       âœrunnerâs            0                0           0           2   \n",
      "19           asberg            1                0           0           2   \n",
      "\n",
      "    contains_non_alphanum  contains_ine            lemma  \\\n",
      "0                       1             0        (versiune   \n",
      "1                       1             0        2001–2005   \n",
      "2                       0             0              25-   \n",
      "3                       0             0        31absence   \n",
      "4                       0             0            50-mg   \n",
      "5                       0             0               50   \n",
      "6                       0             0              5th   \n",
      "7                       1             0                â   \n",
      "8                       0             0        adjuctive   \n",
      "9                       1             0              al.   \n",
      "10                      1             0              am:   \n",
      "11                      0             0         american   \n",
      "12                      0             0            andor   \n",
      "13                      0             0       anecyolypi   \n",
      "14                      0             0    antipsychotic   \n",
      "15                      0             0  anxiolytic-like   \n",
      "16                      1             0      âœeverybody   \n",
      "17                      1             0        âœplanned   \n",
      "18                      1             0       âœrunnerâs   \n",
      "19                      0             0           asberg   \n",
      "\n",
      "    is_real_word_enchant  num_characters  starts_with_letter  \\\n",
      "0                      0               9                   0   \n",
      "1                      0               9                   0   \n",
      "2                      1               3                   0   \n",
      "3                      0               9                   0   \n",
      "4                      1               5                   0   \n",
      "5                      1               3                   0   \n",
      "6                      1               3                   0   \n",
      "7                      0               1                   0   \n",
      "8                      0               9                   1   \n",
      "9                      1               3                   1   \n",
      "10                     0               3                   1   \n",
      "11                     1               8                   1   \n",
      "12                     0               5                   1   \n",
      "13                     0              10                   1   \n",
      "14                     1              14                   1   \n",
      "15                     0              15                   1   \n",
      "16                     0              11                   0   \n",
      "17                     0               9                   0   \n",
      "18                     0              10                   0   \n",
      "19                     0               6                   1   \n",
      "\n",
      "    ends_with_letter  contains_medical_term  \n",
      "0                  1                      0  \n",
      "1                  0                      0  \n",
      "2                  0                      0  \n",
      "3                  1                      0  \n",
      "4                  1                      1  \n",
      "5                  1                      0  \n",
      "6                  1                      0  \n",
      "7                  0                      0  \n",
      "8                  1                      0  \n",
      "9                  0                      1  \n",
      "10                 0                      0  \n",
      "11                 1                      0  \n",
      "12                 1                      0  \n",
      "13                 1                      0  \n",
      "14                 1                      0  \n",
      "15                 1                      1  \n",
      "16                 1                      0  \n",
      "17                 1                      0  \n",
      "18                 1                      0  \n",
      "19                 1                      1  \n"
     ]
    }
   ],
   "source": [
    "valid_words_df = pd.read_csv(\"input_files/valid_words_labelled.csv\")\n",
    "\n",
    "# create features\n",
    "valid_words_df['contains_number'] = valid_words_df['word'].str.contains(r'\\d').astype(int)\n",
    "valid_words_df['num_dashes'] = valid_words_df['word'].str.count('-')\n",
    "valid_words_df['num_vowels'] = valid_words_df['word'].str.count(r'[aeiouAEIOU]')\n",
    "valid_words_df['contains_non_alphanum'] = valid_words_df['word'].str.contains(r'[^a-zA-Z0-9-]').astype(int)\n",
    "valid_words_df['contains_ine'] = valid_words_df['word'].str.contains(r'ine', case=False).astype(int)\n",
    "\n",
    "pos_tags = valid_words_df['word'].apply(lambda x: nltk.pos_tag([x])[0])\n",
    "valid_words_df['lemma'] = pos_tags.apply(lambda x: utils.lemmatize_token(x[0], x[1]))\n",
    "valid_words_df['is_real_word_enchant'] = valid_words_df['lemma'].apply(utils.is_in_enchant_dict).astype(int)\n",
    "\n",
    "valid_words_df['num_characters'] = valid_words_df['word'].apply(len)\n",
    "# Create the 'starts_with_letter' feature\n",
    "valid_words_df['starts_with_letter'] = valid_words_df['word'].apply(lambda x: int(bool(re.match(r'^[A-Za-z]', x))))\n",
    "valid_words_df['ends_with_letter'] = valid_words_df['word'].apply(lambda x: int(bool(re.search(r'[A-Za-z]$', x))))\n",
    "\n",
    "# List of medical terms to check\n",
    "medical_terms = ['-mg', 'dsm', 'dsm-', 'dsm-5', 'dsm-iii', 'cochrane', 'pdd', 'al.', 'prisma', 'asberg', 'cgi', 'qigong', 'subscale', 'waitlist', 'anxiolytic']  # Extend as needed\n",
    "\n",
    "# Function to check if a string contains any of the medical terms\n",
    "def contains_medical_term(word):\n",
    "    return any(term in word for term in medical_terms)\n",
    "\n",
    "valid_words_df['contains_medical_term'] = valid_words_df['word'].apply(contains_medical_term).astype(int)\n",
    "\n",
    "print(f\"\\nLen dataset for model: {len(valid_words_df.index)}\")\n",
    "print(f\"\\n{valid_words_df.columns}\")\n",
    "print(f\"\\n----- {pos_tags[:15]}\")\n",
    "print(\"\\n\")\n",
    "print( valid_words_df.head(20) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valid word classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Index(['contains_number', 'num_dashes', 'num_vowels', 'contains_non_alphanum',\n",
      "       'contains_ine', 'is_real_word_enchant', 'num_characters',\n",
      "       'starts_with_letter', 'ends_with_letter', 'contains_medical_term'],\n",
      "      dtype='object')\n",
      "177\n",
      "177\n",
      "\n",
      "Num features: binary 7 + numeric 3\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = valid_words_df.drop(columns=['valid_label', 'word', 'lemma'])\n",
    "y = valid_words_df['valid_label']\n",
    "\n",
    "print(\"\\n-----\")\n",
    "print(X.columns)\n",
    "print(len(X.index))\n",
    "print(len(y))\n",
    "\n",
    "# Identify binary and non-binary features\n",
    "binary_features = ['contains_number', 'contains_non_alphanum', 'contains_ine', 'ends_with_letter', 'starts_with_letter', 'is_real_word_enchant', 'contains_medical_term']\n",
    "continuous_features = ['num_vowels', 'num_characters', 'num_dashes']\n",
    "print(f\"\\nNum features: binary {len(binary_features)} + numeric {len(continuous_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [1.         0.94444444 0.88888889 0.94444444 0.77777778 0.94444444\n",
      " 1.         0.88235294 1.         1.        ]\n",
      "Mean Accuracy: 0.9382352941176471\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Standardize continuous features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), continuous_features),\n",
    "        ('passthrough', 'passthrough', binary_features)  # Leave binary features as-is\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and logistic regression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, C=1.0))  # Adjust C for regularization strength\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[81  7]\n",
      " [ 4 85]]\n",
      "\n",
      "False Negatives (FN):\n",
      "          word  valid_label\n",
      "51       dsm-5            1\n",
      "52     dsm-iii            1\n",
      "81  interrater            1\n",
      "98          mg            1\n",
      "\n",
      "False Positives (FP):\n",
      "             word  valid_label\n",
      "13     anecyolypi            0\n",
      "70             gi            0\n",
      "72        goodwin            0\n",
      "79             ii            0\n",
      "82   inventory-ii            0\n",
      "121          ovid            0\n",
      "149         rocha            0\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation and get predictions\n",
    "y_pred = cross_val_predict(pipeline, X, y, cv=10)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Identify false negatives (FN) and false positives (FP)\n",
    "FN_indices = (y == 1) & (y_pred == 0)  # True label is 1, predicted as 0\n",
    "FP_indices = (y == 0) & (y_pred == 1)  # True label is 0, predicted as 1\n",
    "\n",
    "# Extract examples of FN and FP from the original dataframe\n",
    "FN_examples = valid_words_df[FN_indices]\n",
    "FP_examples = valid_words_df[FP_indices]\n",
    "\n",
    "# Print false negative examples\n",
    "print(\"\\nFalse Negatives (FN):\")\n",
    "print(FN_examples[['word', 'valid_label']])  # Adjust columns as needed\n",
    "\n",
    "# Print false positive examples\n",
    "print(\"\\nFalse Positives (FP):\")\n",
    "print(FP_examples[['word', 'valid_label']])  # Adjust columns as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run model on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Dataset Confusion Matrix:\n",
      " [[80  8]\n",
      " [ 2 87]]\n",
      "\n",
      "False Negatives (FN):\n",
      "       word  valid_label\n",
      "51    dsm-5            1\n",
      "52  dsm-iii            1\n",
      "\n",
      "False Positives (FP):\n",
      "             word  valid_label\n",
      "13     anecyolypi            0\n",
      "70             gi            0\n",
      "72        goodwin            0\n",
      "79             ii            0\n",
      "82   inventory-ii            0\n",
      "121          ovid            0\n",
      "149         rocha            0\n",
      "157   sportdiscus            0\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the entire dataset\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(\"\\nComplete Dataset Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Identify false negatives (FN) and false positives (FP)\n",
    "FN_indices = (y == 1) & (y_pred == 0)  # True label is 1, predicted as 0\n",
    "FP_indices = (y == 0) & (y_pred == 1)  # True label is 0, predicted as 1\n",
    "\n",
    "# Extract examples of FN and FP from the original dataframe\n",
    "FN_examples = valid_words_df[FN_indices]\n",
    "FP_examples = valid_words_df[FP_indices]\n",
    "\n",
    "# Print false negative examples\n",
    "print(\"\\nFalse Negatives (FN):\")\n",
    "print(FN_examples[['word', 'valid_label']])  # Adjust columns as needed\n",
    "\n",
    "# Print false positive examples\n",
    "print(\"\\nFalse Positives (FP):\")\n",
    "print(FP_examples[['word', 'valid_label']])  # Adjust columns as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Cross-Validation Accuracy Scores: [0.77777778 0.88888889 0.88888889 0.94444444 0.83333333 1.\n",
      " 1.         0.76470588 0.94117647 1.        ]\n",
      "SVM Mean Accuracy: 0.903921568627451\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with SVM (RBF kernel) using the existing preprocessor\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Reuse existing preprocessor\n",
    "    ('classifier', SVC(kernel='rbf', C=1.0, gamma='scale', probability=True))\n",
    "])\n",
    "\n",
    "# Perform cross-validation (accuracy)\n",
    "svm_cv_scores = cross_val_score(svm_pipeline, X, y, cv=10, scoring='accuracy')\n",
    "print(\"SVM Cross-Validation Accuracy Scores:\", svm_cv_scores)\n",
    "print(\"SVM Mean Accuracy:\", svm_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Confusion Matrix:\n",
      " [[79  9]\n",
      " [ 8 81]]\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.91      0.90      0.90        88\n",
      "     Class 1       0.90      0.91      0.91        89\n",
      "\n",
      "    accuracy                           0.90       177\n",
      "   macro avg       0.90      0.90      0.90       177\n",
      "weighted avg       0.90      0.90      0.90       177\n",
      "\n",
      "\n",
      "False Negatives (FN):\n",
      "       word  valid_label\n",
      "51    dsm-5            1\n",
      "52  dsm-iii            1\n",
      "\n",
      "False Positives (FP):\n",
      "             word  valid_label\n",
      "13     anecyolypi            0\n",
      "70             gi            0\n",
      "72        goodwin            0\n",
      "79             ii            0\n",
      "82   inventory-ii            0\n",
      "121          ovid            0\n",
      "149         rocha            0\n",
      "157   sportdiscus            0\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation predictions\n",
    "y_pred_svm = cross_val_predict(svm_pipeline, X, y, cv=10)\n",
    "\n",
    "# Evaluate performance using confusion matrix and classification report\n",
    "svm_conf_matrix = confusion_matrix(y, y_pred_svm)\n",
    "print(\"\\nSVM Confusion Matrix:\\n\", svm_conf_matrix)\n",
    "\n",
    "svm_class_report = classification_report(y, y_pred_svm, target_names=['Class 0', 'Class 1'])\n",
    "print(\"\\nSVM Classification Report:\\n\", svm_class_report)\n",
    "\n",
    "# Identify false negatives (FN) and false positives (FP)\n",
    "FN_indices = (y == 1) & (y_pred == 0)  # True label is 1, predicted as 0\n",
    "FP_indices = (y == 0) & (y_pred == 1)  # True label is 0, predicted as 1\n",
    "\n",
    "# Extract examples of FN and FP from the original dataframe\n",
    "FN_examples = valid_words_df[FN_indices]\n",
    "FP_examples = valid_words_df[FP_indices]\n",
    "\n",
    "# Print false negative examples\n",
    "print(\"\\nFalse Negatives (FN):\")\n",
    "print(FN_examples[['word', 'valid_label']])  # Adjust columns as needed\n",
    "\n",
    "# Print false positive examples\n",
    "print(\"\\nFalse Positives (FP):\")\n",
    "print(FP_examples[['word', 'valid_label']])  # Adjust columns as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to create features for token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier model integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean summary function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NPR2-42-120.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the folder containing the PDFs\n",
    "pdf_folder = 'pdf_files'\n",
    "\n",
    "# List all files in the pdf_folder and filter to include only PDFs\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "print(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Effects of lamotrigine on unipolar depression.\",\n",
    "    \"Impact of lamotrigine on unipolar depression.\",\n",
    "    \"Key findings related to lamotrigine in treating unipolar depression.\",\n",
    "    \"Outcomes and statistics related to lamotrigine and unipolar depression.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the summaries\n",
    "summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file: pdf_files\\NPR2-42-120.pdf\n",
      "Extracted text for Page 1:\n",
      " Received: 17 April 2021 | Revised: 12 November 2021 | Accepted: 15 December 2021DOI: 10.1002/npr2.12228CASE REPORTThe effectiveness of lamotrigine for persistent depressivedisorder: A case reportYusuke Matsuzaka1,2 | Kayoko Urashima1,2 | Shintaro Sakai1 | Yoshiro Morimoto1,2 |Shinji Kanegae1 | Hirohisa Kinoshita1,3 | Akira Imamura1,4 | Hiroki Ozawa1,21Department of Neuropsychiatry,Nagasaki University Hospital, Nagasaki, AbstractJapan Aim: Persistent depressive disorder (PDD) was first introduced in the Diagnostic and2Department of Neuropsychiatry, Statistical Manual of Mental Disorders 5th edition (DSM-5), which encompasses nu-Nagasaki University Graduate School ofBiomedical Sciences, Nagasaki, Japan merous different conditions, including dysthymia, recurrent major depressive disor-3Health Center, Nagasaki University, der, double depression, and chronic major depression. SSRIs are the first-line drugs forNagasaki, Japantreatment of PDD; however, not all patients respond to SSRI treatment.4Child and Adolescent PsychiatryCommunity Partnership Unit, Nagasaki Case presentation: We describe a woman who was diagnosed with PDD. At the ageUniversity Hospital, Nagasaki, Japan of 38, the patient presented with anxiety, reduced energy, marked tiredness, andCorrespondence sleep disturbances. She was prescribed with three antidepressants (paroxetine, du-Yusuke Matsuzaka, Department of loxetine, and mirtazapine), which were not effective in relieving her symptoms. SheNeuropsychiatry, Nagasaki UniversityGraduate School of Biomedical Sciences, was also prescribed bromazepam, which was also not effective. Subsequently, she852-8501, 1-7-1 Sakamoto, Nagasaki, was switched to lamotrigine, which resulted in a marked improvement in symptoms.Japan.Email: ysk.mtzk.1980@gmail.com The antidepressants and bromazepam were gradually tapered and discontinued.Conclusion: This case demonstrates that lamotrigine may be effective for treatingFunding informationThis work was supported by the Japan patients with antidepressant resistant PDD and suggests that it may be a promis-Society for the Promotion of Science ing alternative to combination therapy of antidepressants and benzodiazepines in the(JSPS) KAKENHI (grant number20K16629) (to Yu. M). treatment of PDD.KEYWORDSbipolar and related disorders, lamotrigine, persistent depressive disorder (PDD)1 | INTRODUCTION heterogeneity of the diagnosis, and these criticisms have continuedwith PDD, its latest classification. Several reports have examined thePersistent depressive disorder (PDD) was first introduced in the efficacy and acceptability of selective serotonin reuptake inhibitorsDiagnostic and Statistical Manual of Mental Disorders 5th edition (SSRIs) and tricyclic antidepressants in the treatment of PDD1 and(DSM-5), which encompasses numerous different conditions, in- have provided evidence for the efficacy of antidepressants in thecluding dysthymia (DST), recurrent major depressive disorder, dou- treatment of chronic depression. However, reports have shown thatble depression, and chronic major depression. Since its inception up to two-thirds of adult patients do not achieve remission with SSRIin the DSM-III, DST has been widely criticized for its significant treatment. Moreover, there is limited evidence identifying reliableThis is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium,provided the original work is properly cited.© 2022 The Authors. Neuropsychopharmacology Reports published by John Wiley & Sons Australia, Ltd on behalf of The Japanese Society ofNeuropsychopharmacology|120 wileyonlinelibrary.com/journal/nppr Neuropsychopharmacology Reports. 2022;42:120–123. \n",
      "--------------------------------------------------------------------------------\n",
      "Extracted text for Page 2:\n",
      " MATSUZAKA eT Al. | 121predictors (eg, demographic, clinical, or genetic characteristics) of was prescribed maximum doses of paroxetine, duloxetine, and mir-individual response.2,3 Therefore, effective treatment of patients tazapine; however, her symptoms did not improve. Furthermore,with PDD who do not respond to SSRIs remains elusive. she was prescribed the maximum dose of bromazepam for anxi-Here, we report a patient who was diagnosed with PDD who ety, but her anxiety symptoms persisted. Although the patient hadshowed insufficient improvement with a combination therapy of an- treatment resistance to antidepressants, she did not experiencetidepressants but achieved remission with lamotrigine monotherapy. severe depressive symptoms (such as suicidal ideation) or psy-chotic symptoms (such as delusions); thus, augmentation therapywith antipsychotics and electroconvulsive therapy were consid-2 | CASE REPORT ered unsuitable. Subsequently, she was treated with lamotrigineand her symptoms of depressions stabilized. The three antidepres-The patient was a woman in her 50’s. Her mother, grandmother, sants were gradually tapered and discontinued. Her anxiety alsoand aunt were diagnosed with major depressive disorder and com- improved dramatically, and bromazepam was gradually taperedmitted suicide. She worked in a hospital as a nurse. At the age of and discontinued. Remission was maintained for over 2 years, and38 years, she began experiencing fatigue and wobble. She visited she was reemployed as a care insurance investigator.a general medicine clinic, but no abnormalities were detected. She Detailed information of the patient's symptoms (measured usingpresented with symptoms of depression (eg, depressed mood, the Cornell Dysthymia Rating Scale4) is summarized in Table 1.reduced energy, pessimism, and sleep disturbances). She did notpresent with hypomanic or manic symptoms, such as mood eleva-tion. At the psychiatry clinic, she was diagnosed with major de- 3 | DISCUSSIONpressive disorder and was started on paroxetine. However, hersymptoms remained unstable, and she remitted and relapsed re- Lamotrigine has not showed efficacy in the treatment of unipolarpeatedly. Her diagnosis was revised from major depressive disor- depression.5,6 This case provided the new findings that lamotrigineder to PDD, and duloxetine and mirtazapine were added to her improved unipolar depression resistant to antidepressants and alsotreatment when she was aged 45 and 46 years, respectively. She improved anxiety symptoms being free from benzodiazepines.TABLE 1 Clinical information ofCombination therapy (paroxetine,the patients according to the Cornellduloxetine, mirtazapine, andDysthymia Rating ScaleItem bromazepam) LamotrigineDepressed mood 4 1Lack of interest or pleasure 3 0Pessimism 2 0Suicidal ideation 0 0Low self-esteem 3 1Guilt 2 0Helplessness 3 0Social withdrawal 3 0Indecisiveness 2 0Low attention and concentration 3 0Psychic anxiety 4 1Somatic anxiety 3 0Worry 3 1Irritability or excessive anger 2 0Somatic general 3 0Low productivity 3 0Low energy 4 0Low sexual interest, activity 2 0Sleep disturbance 3 1Diurnal mood variation 3 1Total 55 6Note: After switching to lamotrigine monotherapy, the symptoms have improved and continuedremission for a long time. \n",
      "--------------------------------------------------------------------------------\n",
      "Extracted text for Page 3:\n",
      " 122 | MATSUZAKA eT Al.Our patient presented with two contradictory aspects: (a) She CONFLICT OF INTERESTmet criteria for PDD according to the DSM-5 but did not meet None.criteria for bipolar disorder; and (b) although she did not show im-provement with antidepressant treatment, remission was achieved AUTHOR CONTRIBUTIONSfollowing therapy with a mood stabilizer, lamotrigine. There are Yu. M. treated the patient and drafted the manuscript. Yo. M. criti-several guidelines that recommend mood stabilizers for treating pa- cally reviewed the draft and revised it. All authors made substan-tients with depressive disorder based on the recognition of bipolar tial contributions, drafted the manuscript, and approved the finaldisorder as a broad-spectrum disorder that encompasses depressive manuscript.disorder.7–9 Moreover, PDD is thought to be a predictive factor forbipolar disorder, alongside family history of bipolar disorder and cy- INFORMED CONSENTclothymic temperament.10 Therefore, the concepts of bipolar disor- Written consent from the patient was obtained.der and PDD need to be considered carefully.There has been limited discussion around the use of mood stabi- DATA AVAILABILITY STATEMENTlizers for the treatment of PDD. Most mood stabilizers are effective Data sharing is not applicable to this article as no datasets were gen-for managing manic states, but they are not effective for resolving erated or analyzed during the current study.depressive states. However, lamotrigine is effective for the treat-ment of bipolar depression and has a low risk of manic switch.11 ORCIDFurthermore, lamotrigine has a therapeutic effect on depressive Yusuke Matsuzaka https://orcid.org/0000-0002-3552-7297cognition and psychomotor retardation in patients with bipolar Yoshiro Morimoto https://orcid.org/0000-0002-0636-277Xdepression.12 Therefore, the use of lamotrigine in the treatment of Hirohisa Kinoshita https://orcid.org/0000-0002-9077-1612PDD may be useful in regard to efficacy and safety. In animal mod-els, the blocking of sodium channels was related to improving de- REFERENCESpressive symptom.13 1. Carta MG, Paribello P, Nardi AE, Preti A. Current pharmacothera-Interestingly, our patient presented with depression-related peutic approaches for dysthymic disorder and persistent depres-sive disorder. Expert Opin Pharmacother. 2019;20(14):1743–54.anxiety, which also improved with lamotrigine. Anxiety frequently2. von Wolff A, Hölzel LP, Westphal A, Härter M, Kriston L. Selectivecoexists with depression, and the addition of benzodiazepines to an- serotonin reuptake inhibitors and tricyclic antidepressantstidepressant treatment is common practice in treatments for major in the acute treatment of chronic depression and dysthy-depression. Reports have shown that combination therapy with anti- mia: a systematic review and meta-analysis. J Affect Disord.2013;144(1–2):7–15.depressants and benzodiazepines is more effective than antidepres-3. Santaguida PL, MacQueen G, Keshavarz H, Levine M, Beyene J,sant monotherapy for improving the severity, treatment response, Raina P. Treatment for Depression After Unsatisfactory Responseand remission in the early stages of depression.14 However, in our to SSRIs [internet]. Rockville (MD): Agency for Healthcarecase, combination therapy of antidepressants and benzodiazepines Research and Quality (US) Report No.: 12-EHC050-EF; 2012 Apr.Available from: https://www.ncbi.nlm.nih.gov/books/NBK97was not effective. Moreover, animal models have revealed that lam-406/otrigine has an anxiolytic-like pharmacokinetic profile that may be 4. Cohen J. Assessment and treatment of dysthymia. The devel-related to sodium channels.15 Taken together, we suggest that lamo- opment of the Cornell dysthymia rating scale. Eur Psychiatry.trigine is a promising alternative to benzodiazepines in the treatment 1997;12(4):190–3.5. Amann B, Born C, Crespo JM, Pomarol-Clotet E, McKenna P.of PDD.Lamotrigine: when and where does it act in affective disorders? AThe plasma concentration of lamotrigine has not been measured systematic review. J Sychopharmacol. 2011;25(10):1289–94.in this case. Therapeutic response to lamotrigine occurs when its 6. Reid JG, Gitlin MJ, Altshuler LL. Lamotrigine in psychiatric disor-plasma concentration is higher than 12.7 μmol/L.16 This response ders. J Clin Psychiatry. 2013;74(7):675–84.was derived in 75-100 mg dosage, so our patient might have suffi- 7. Ghaemi SN. Bipolar spectrum: a review of the concept and a visionfor the future. Psychiatry Investig. 2013;10(3):218–24.cient therapeutic effect of lamotrigine with 200 mg.8. Hantouche EG, Angst J, Akiskal HS. Factor structure of hypomania:In summary, our case demonstrated that lamotrigine may be ef- interrelationships with cyclothymia and the soft bipolar spectrum.fective in patients with PDD who are resistant to antidepressants. J Affect Disord. 2003;73(1–2):39–47.Moreover, lamotrigine may be a promising alternative to combination 9. Akiskal HS. Validating 'hard' and 'soft' phenotypes within the bi-polar spectrum: continuity or discontinuity? J Affect Disord.therapy of antidepressants and benzodiazepines in the treatment2003;73(1–2):1–5.of PDD. Fully understanding the homogeneity and heterogeneity 10. Takeshima M, Oka T. A comprehensive analysis of features thatof bipolar disorder and PDD requires further clinical and biological suggest bipolarity in patients with a major depressive episode:investigations. Nevertheless, we believe that our case provides an which is the best combination to predict soft bipolarity diagnosis? JAffect Disord. 2013;147(1–3):150–5.opportunity to further our understanding of these disorders.11. Calabrese JR, Bowden CL, Sachs GS, Ascher JA, Monaghan E,Rudd GD. A double-blind placebo-controlled study of lamotrigineACKNOWLEDGMENT monotherapy in outpatients with bipolar I depression. Lamictal 602We thank the patient for participating in this study. Study Group. J Clin Psychiatry. 1999;60(2):79–88. \n",
      "--------------------------------------------------------------------------------\n",
      "Extracted text for Page 4:\n",
      " MATSUZAKA eT Al. | 12312. Mitchell PB, Hadzi-Pavlovic D, Evoniuk G, Calabrese JR, Bowden 16. Kagawa S, Mihara K, Nakamura A, et al. Relationship betweenCL. A factor analytic study in bipolar depression, and response to plasma concentrations of lamotrigine and its early therapeutic ef-lamotrigine. CNS Spectr. 2013;18(4):214–24. fect of lamotrigine augmentation therapy in treatment resistant13. Prica C, Hascoet M, Bourin M. Antidepressant-like effect of lamo- depressive disorder. Ther Drug Monit. 2014;36(6):730–3.trigine is reversed by veratrine: a possible role of sodium channelsin bipolar depression. Behav Brain Res. 2008;191:49–54.14. Ogawa Y, Takeshima N, Hayasaka Y, Tajika A, Watanabe N, Streiner How to cite this article: Matsuzaka Y, Urashima K, Sakai S,D, et al. Antidepressants plus benzodiazepines for adults with majorMorimoto Y, Kanegae S, Kinoshita H, et al. The effectivenessdepression. Cochrane Database Syst Rev. 2019;6(6):CD001026.15. Mirza NR, Bright JL, Stanhope KJ, Wyatt A, Harrington NR. of lamotrigine for persistent depressive disorder: A caseLamotrigine has an anxiolytic-like profile in the rat conditioned report. Neuropsychopharmacol Rep. 2022;42:120–123.emotional response test of anxiety: a potential role for sodium https://doi.org/10.1002/npr2.12228channels? Psychopharmacology. 2005;180(1):159–68. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pdf_folder = \"pdf_files\"  # Replace with your actual folder name\n",
    "\n",
    "# Select the first PDF file and process it\n",
    "ind = 0\n",
    "curr_file_path = os.path.join(pdf_folder, pdf_files[ind])  # First file\n",
    "print(f\"Current file: {curr_file_path}\")\n",
    "\n",
    "# Open the PDF and extract text page-by-page\n",
    "with open(curr_file_path, 'rb') as file:\n",
    "    pages_text = utils.read_pdf_by_page(file)  # Get text for each page separately\n",
    "\n",
    "# Save each page's text to separate files (optional)\n",
    "for i, page_text in enumerate(pages_text):\n",
    "    with open(f\"page_{i + 1}_text.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(page_text)\n",
    "\n",
    "# print('\\n', curr_file_text)\n",
    "# print('\\n', extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load txt files - processing start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adel_Gabriel_Lamotrigine_2006.txt', 'exercise_depression_2024_au.txt', 'matsuzaka_lamotrigine_2021.txt']\n"
     ]
    }
   ],
   "source": [
    "txt_folder = 'txt_files'\n",
    "\n",
    "txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current file: txt_files\\exercise_depression_2024_au.txt \n",
      "\n",
      "Introduction\n",
      "Major depressive disorder is a leading cause of\n",
      "disability worldwide and has been found to lower life\n",
      "satisfaction more than debt, divorce, and diabetes and to exacerbate comorbidities, including heart\n",
      "disease, anxiety, and cancer. Although people with\n",
      "major depressive disorder often respond well to drug\n",
      "treatments and psychotherapy, many are resistant to\n",
      "treatment. In addition, access to treatment for many\n",
      "people with depression is limited, with only 51%\n",
      "treatment coverage for high income countries and 20%\n",
      "for low and lower-middle income countries. More\n",
      "evidence based treatments are therefore needed.\n",
      "Exercise may be an effective complement or\n",
      "alternative to drugs and psychotherapy. In addition\n",
      "to mental health benefits, exercise also improves a\n",
      "range of physical and cognitive outcomes. Clinical\n",
      "practice guidelines in the US, UK, and Australia\n",
      "recommend physical activity as part of treatment for\n",
      "depression. But these guidelines do not provide\n",
      "clear, consistent recommendations about dose or\n",
      "exercise modality. British guidelines recommend\n",
      "group exercise programmes and offer general\n",
      "recommendations to increase any form of physical\n",
      "activity, the American Psychiatric Association\n",
      "recommends any dose of aerobic exercise or resistance\n",
      "training, and Australian and New Zealand guidelines suggest a combination of strength and vigorous aerobic\n",
      "exercises, with at least two or three bouts weekly. Authors of guidelines may find it hard to provide\n",
      "consistent recommendations on the basis of existing\n",
      "mainly pairwise meta-analyses—that is, assessing\n",
      "a specific modality versus a specific comparator in\n",
      "a distinct group of participants. These meta-analyses have come under scrutiny for pooling\n",
      "heterogeneous treatments and heterogenous\n",
      "comparisons leading to ambiguous effect estimates. Reviews also face the opposite problem, excluding\n",
      "exercise treatments such as yoga, tai chi, and qigong because grouping them with strength training might\n",
      "be inappropriate. Overviews of reviews have tried\n",
      "to deal with this problem by combining pairwise\n",
      "meta-analyses on individual treatments. A recent\n",
      "such overview found no differences between exercise\n",
      "modalities. Comparing effect sizes between different\n",
      "pairwise meta-analyses can also lead to confusion\n",
      "because of differences in analytical methods used\n",
      "between meta-analysis, such as choice of a control\n",
      "to use as the referent. Network meta-analyses\n",
      "are a better way to precisely quantify differences\n",
      "between interventions as they simultaneously model the direct and indirect comparisons between\n",
      "interventions. Network meta-analyses have been used to compare\n",
      "different types of psychotherapy and pharmacotherapy\n",
      "for depression. For exercise, they have shown that\n",
      "dose and modality influence outcomes for cognition, back pain, and blood pressure. Two network meta-analyses explored the effects of exercise on depression:\n",
      "one among older adults and the other for mental\n",
      "health conditions. Because of the inclusion criteria\n",
      "and search strategies used, these reviews might have\n",
      "been under-powered to explore moderators such as\n",
      "dose and modality (κ=15 and κ=71, respectively).\n",
      "To resolve conflicting findings in existing reviews,\n",
      "we comprehensively searched randomised trials on\n",
      "exercise for depression to ensure our review was\n",
      "adequately powered to identify the optimal dose and\n",
      "modality of exercise. For example, a large overview of\n",
      "reviews found effects on depression to be proportional\n",
      "to intensity, with vigorous exercise appearing to be\n",
      "better, but a later meta-analysis found no such\n",
      "effects. We explored whether recommendations\n",
      "differ based on participants’ sex, age, and baseline\n",
      "level of depression. Given the challenges presented by behaviour\n",
      "change in people with depression, we also identified\n",
      "autonomy support or behaviour change techniques\n",
      "that might improve the effects of intervention. Behaviour change techniques such as self-monitoring\n",
      "and action planning have been shown to influence the\n",
      "effects of physical activity interventions in adults (>18\n",
      "years) and older adults (>60 years) with differing\n",
      "effectiveness of techniques in different populations. We\n",
      "therefore tested whether any intervention components\n",
      "from the behaviour change technique taxonomy were\n",
      "associated with higher or lower intervention effects. Other meta-analyses found that physical activity\n",
      "interventions work better when they provide people\n",
      "with autonomy (eg, choices, invitational language).\n",
      "Autonomy is not well captured in the taxonomy for\n",
      "behaviour change technique. We therefore tested\n",
      "whether effects were stronger in studies that provided\n",
      "more autonomy support to patients. Finally, to\n",
      "understand the mechanism of intervention effects,\n",
      "such as self-confidence, affect, and physical fitness, we\n",
      "collated all studies that conducted formal mediation\n",
      "analyses.\n",
      "Methods.\n",
      "Our findings are presented according to the Preferred\n",
      "Reporting Items for Systematic Reviews and MetaAnalyses-Network Meta-analyses (PRISMA-NMA)\n",
      "guidelines (see supplementary file, section S0; all\n",
      "supplementary files, data, and code are also available\n",
      "at https://osf.io/nzw6u/). We amended our analysis\n",
      "strategy after registering our review; these changes\n",
      "were to better align with new norms established\n",
      "by the Cochrane Comparing Multiple Interventions\n",
      "Methods Group. These norms were introduced\n",
      "between the publication of our protocol and the\n",
      "preparation of this manuscript. The largest change was using the confidence in network meta-analysis\n",
      "(CINeMA) online tool instead of the Grading of\n",
      "Recommendations, Assessment, Development and\n",
      "Evaluation (GRADE) guidelines and adopting methods\n",
      "to facilitate assessments—for example, instead of\n",
      "using an omnibus test for all treatments, we assessed\n",
      "publication bias for each treatment compared with\n",
      "active controls. We also modelled acceptability\n",
      "(through dropout rate), which was not predefined but\n",
      "was adopted in response to a reviewer’s comment.\n",
      "Eligibility criteria.\n",
      "To be eligible for inclusion, studies had to be\n",
      "randomised controlled trials that included exercise as\n",
      "a treatment for depression and included participants\n",
      "who met the criteria for major depressive disorder,\n",
      "either clinician diagnosed or identified through\n",
      "participant self-report as exceeding established clinical\n",
      "thresholds (eg, scored >13 on the Beck depression\n",
      "inventory-II). Studies could meet these criteria\n",
      "when all the participants had depression or when the\n",
      "study reported depression outcomes for a subgroup of\n",
      "participants with depression at the start of the study.\n",
      "We defined exercise as “planned, structured\n",
      "and repetitive bodily movement done to improve\n",
      "or maintain one or more components of physical\n",
      "fitness.” Unlike recent reviews, we included\n",
      "studies with more than one exercise arm and\n",
      "multifaceted interventions (eg, health and exercise\n",
      "counselling) as long as they contained a substantial\n",
      "exercise component. These trials could be included\n",
      "because network meta-analysis methods allows for\n",
      "the grouping of those interventions into homogenous\n",
      "nodes. Unlike the most recent Cochrane review, we\n",
      "also included participants with physical comorbidities\n",
      "such as arthritis and participants with postpartum\n",
      "depression because the Diagnostic Statistical Manual\n",
      "of Mental Health Disorders, fifth edition, removed the\n",
      "postpartum onset specifier after that analysis was\n",
      "completed. Studies were excluded if interventions\n",
      "were shorter than one week, depression was not\n",
      "reported as an outcome, and data were insufficient to\n",
      "calculate an effect size for each arm. Any comparison\n",
      "condition was included, allowing us to quantify the\n",
      "effects against established treatments (eg, selective\n",
      "serotonin reuptake inhibitors (SSRIs), cognitive\n",
      "behavioural therapy), active control conditions (usual\n",
      "care, placebo tablet, stretching, educational control,\n",
      "and social support), or waitlist control conditions.\n",
      "Published and unpublished studies were included,\n",
      "with no restrictions on language applied.\n",
      "Information sources.\n",
      "We adapted the search strategy from the most recent\n",
      "Cochrane review, adding keywords for yoga, tai chi,\n",
      "and qigong, as they met our definition for exercise.\n",
      "We conducted database searches, without filters or\n",
      "date limits, in The Cochrane Library via CENTRAL,\n",
      "SPORTDiscus via Embase, and Medline, Embase, and\n",
      "PsycINFO via Ovid. We assessed\n",
      "full texts of all included studies from two systematic\n",
      "reviews of exercise for depression.\n",
      "Results.\n",
      "Study selection.\n",
      "The PRISMA flow diagram outlines the study selection\n",
      "process (fig 1). We used two previous reviews to identify\n",
      "potentially eligible studies for inclusion. Database\n",
      "searches identified 18658 possible studies. After\n",
      "5505 duplicates had been removed, two reviewers\n",
      "independently screened 13115 titles and abstracts.\n",
      "After screening, two reviewers independently reviewed\n",
      "1738 full text articles. Supplementary file section S2\n",
      "shows the consensus reasons for exclusion. A total\n",
      "of 218 unique studies described in 246 reports were\n",
      "included, totalling 495 arms and 14170 participants.\n",
      "Supplementary file section S3 lists the references and\n",
      "characteristics of the included studies.\n",
      "Discussion.\n",
      "Summary of evidence.\n",
      "In this systematic review and meta-analysis of\n",
      "randomised controlled trials, exercise showed\n",
      "moderate effects on depression compared with active controls, either alone or in combination with\n",
      "other established treatments such as cognitive\n",
      "behaviour therapy. In isolation, the most effective\n",
      "exercise modalities were walking or jogging, yoga,\n",
      "strength training, and dancing. Although walking\n",
      "or jogging were effective for both men and women,\n",
      "strength training was more effective for women,\n",
      "and yoga or qigong was more effective for men. Yoga\n",
      "was somewhat more effective among older adults,\n",
      "and strength training was more effective among younger people. The benefits from exercise tended\n",
      "to be proportional to the intensity prescribed, with\n",
      "vigorous activity being better. Benefits were equally\n",
      "effective for different weekly doses, for people with\n",
      "different comorbidities, or for different baseline levels\n",
      "of depression. Although confidence in many of the\n",
      "results was low, treatment guidelines may be overly\n",
      "conservative by conditionally recommending exercise\n",
      "as complementary or alternative treatment for patients\n",
      "in whom psychotherapy or pharmacotherapy is either\n",
      "ineffective or unacceptable. Instead, guidelines for\n",
      "depression ought to include prescriptions for exercise\n",
      "and consider adapting the modality to participants’\n",
      "characteristics and recommending more vigorous\n",
      "intensity exercises.\n",
      "Our review did not uncover clear causal\n",
      "mechanisms, but the trends in the data are useful for\n",
      "generating hypotheses. It is unlikely that any single\n",
      "causal mechanism explains all the findings in the\n",
      "review. Instead, we hypothesise that a combination\n",
      "of social interaction, mindfulness or experiential\n",
      "acceptance, increased self-efficacy, immersion in\n",
      "green spaces, neurobiological mechanisms, and\n",
      "acute positive affect combine to generate outcomes.\n",
      "Meta-analyses have found each of these factors to be\n",
      "associated with decreases in depressive symptoms,\n",
      "but no single treatment covers all mechanisms. Some\n",
      "may more directly promote mindfulness (eg, yoga),\n",
      "be more social (eg, group exercise), be conducted in\n",
      "green spaces (eg, walking), provide a more positive\n",
      "affect (eg, “runner’s high”’), or be more conducive to\n",
      "acute adaptations that may increase self-efficacy (eg,\n",
      "strength). Exercise modalities such as running may\n",
      "satisfy many of the mechanisms, but they are unlikely\n",
      "to directly promote the mindful self-awareness\n",
      "provided by yoga and qigong. Both these forms of\n",
      "exercise are often practised in groups with explicit\n",
      "mindfulness but seldom have fast and objective\n",
      "feedback loops that improve self-efficacy. Adequately\n",
      "powered studies testing multiple mediators may help\n",
      "to focus more on understanding why exercise helps\n",
      "depression and less on whether exercise helps. We\n",
      "argue that understanding these mechanisms of action\n",
      "is important for personalising prescriptions and better\n",
      "understanding effective treatments.\n",
      "Our review included more studies than many\n",
      "existing reviews on exercise for depression.\n",
      "As a result, we were able to combine the strengths\n",
      "of various approaches to exercise and to make more\n",
      "nuanced and precise conclusions. For example, even\n",
      "taking conservative estimates (ie, the least favourable\n",
      "end of the credible interval), practitioners can expect\n",
      "patients to experience clinically significant effects\n",
      "from walking, running, yoga, qigong, strength\n",
      "training, and mixed aerobic exercise. Because we\n",
      "simultaneously assessed more than 200 studies,\n",
      "credible intervals were narrower than those in most\n",
      "existing meta-analyses. We were also able to explore\n",
      "non-linear relationships between outcomes and\n",
      "moderators, such as frequency, intensity, and time.\n",
      "These analyses supported some existing findings—for\n",
      "example, our study and the study by Heissel et al\n",
      "found that shorter interventions had stronger effects,\n",
      "at least for six months; our study and the study by\n",
      "Singh et al both found that effects were stronger with\n",
      "vigorous intensity exercise compared with light and\n",
      "moderate exercise. However, most existing reviews\n",
      "found various treatment modalities to be equally\n",
      "effective. In our review, some types of exercise\n",
      "had stronger effect sizes than others. We attribute this\n",
      "to the study level data available in a network metaanalysis compared with an overview of reviews\n",
      "and higher power compared with meta-analyses with\n",
      "smaller numbers of included studies. Overviews of\n",
      "reviews have the ability to more easily cover a wider\n",
      "range of participants, interventions, and outcomes,\n",
      "but also risk double counting randomised trials that\n",
      "are included in separate meta-analyses. They often\n",
      "include heterogeneous studies without having as\n",
      "much control over moderation analyses (eg, Singh\n",
      "et al included studies covering both prevention\n",
      "and treatment). Some of those reviews grouped\n",
      "interventions such as yoga with heterogeneous\n",
      "interventions such as stretching and qigong. This\n",
      "practise of combining different interventions makes\n",
      "it harder to interpret meta-analytical estimates. We\n",
      "used methods that enabled us to separately analyse\n",
      "the effects of these treatment modalities. In so doing,\n",
      "we found that these interventions do have different\n",
      "effects, with yoga being an intervention with strong\n",
      "effects and stretching being better described as an\n",
      "active control condition. Network meta-analyses\n",
      "revealed the same phenomenon with psychotherapy:\n",
      "researchers once concluded there was a dodo bird\n",
      "verdict, whereby “everybody has won, and all must\n",
      "have prizes,” until network meta-analyses showed\n",
      "some interventions were robustly more effective than\n",
      "others.\n",
      "Conclusions.\n",
      "Depression imposes a considerable global burden.\n",
      "Many exercise modalities appear to be effective\n",
      "treatments, particularly walking or jogging, strength\n",
      "training, and yoga, but confidence in many of the\n",
      "findings was low. We found preliminary data that may\n",
      "help practitioners tailor interventions to individuals\n",
      "(eg, yoga for older men, strength training for younger\n",
      "women). The World Health Organization recommends\n",
      "physical activity for everyone, including those with\n",
      "chronic conditions and disabilities, but not everyone\n",
      "can access treatment easily. Many patients may\n",
      "have physical, psychological, or social barriers to\n",
      "participation. Still, some interventions with few costs,\n",
      "side effects, or pragmatic barriers, such as walking\n",
      "and jogging, are effective across people with different\n",
      "personal characteristics, severity of depression, and\n",
      "comorbidities. Those who are able may want to choose\n",
      "more intense exercise in a structured environment to\n",
      "further decrease depression symptoms. Health systems\n",
      "may want to provide these treatments as alternatives or\n",
      "adjuvants to other established interventions (cognitive\n",
      "behaviour therapy, SSRIs), while also attenuating\n",
      "risks to physical health associated with depression.\n",
      "Therefore, effective exercise modalities could be\n",
      "considered alongside those intervention as core\n",
      "treatments for depression.\n"
     ]
    }
   ],
   "source": [
    "ind = 1\n",
    "curr_file = os.path.join(txt_folder, txt_files[ind])\n",
    "print(f\"\\nCurrent file: {curr_file} \\n\")\n",
    "with open(curr_file, 'r', encoding='utf-8') as file:\n",
    "    # file_content = read_txt(file)\n",
    "    file_content = file.read()\n",
    "\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3286 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens in the text: 3286\n"
     ]
    }
   ],
   "source": [
    "# Apply to your file content\n",
    "num_tokens = utils.count_tokens(file_content, tokenizer)\n",
    "\n",
    "print(f\"The number of tokens in the text: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test specific chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Num chunks: 4\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "Introduction Major depressive disorder is a leading cause of disability worldwide and has been found to lower life satisfaction more than debt, divorce, and diabetes and to exacerbate comorbidities, including heart disease, anxiety, and cancer. Although people with major depressive disorder often respond well to drug treatments and psychotherapy, many are resistant to treatment. In addition, access to treatment for many people with depression is limited, with only 51 treatment coverage for high income countries and 20 for low and lower-middle income countries. More evidence based treatments are therefore needed. Exercise may be an effective complement or alternative to drugs and psychotherapy. In addition to mental health benefits, exercise also improves a range of physical and cognitive outcomes. Clinical practice guidelines in the US, UK, and Australia recommend physical activity as part of treatment for depression. But these guidelines do not provide clear, consistent recommendations about dose or exercise modality. British guidelines recommend group exercise programmes and offer general recommendations to increase any form of physical activity, the American Psychiatric Association recommends any dose of aerobic exercise or resistance training, and Australian and New Zealand guidelines suggest a combination of strength and vigorous aerobic exercises, with at least two or three bouts weekly. Authors of guidelines may find it hard to provide consistent recommendations on the basis of existing mainly pairwise meta-analysesthat is, assessing a specific modality versus a specific comparator in a distinct group of participants. These meta-analyses have come under scrutiny for pooling heterogeneous treatments and heterogenous comparisons leading to ambiguous effect estimates. Reviews also face the opposite problem, excluding exercise treatments such as yoga, tai chi, and qigong because grouping them with strength training might be inappropriate. Overviews of reviews have tried to deal with this problem by combining pairwise meta-analyses on individual treatments. A recent such overview found no differences between exercise modalities. Comparing effect sizes between different pairwise meta-analyses can also lead to confusion because of differences in analytical methods used between meta-analysis, such as choice of a control to use as the referent. Network meta-analyses are a better way to precisely quantify differences between interventions as they simultaneously model the direct and indirect comparisons between interventions. Network meta-analyses have been used to compare different types of psychotherapy and pharmacotherapy for depression. For exercise, they have shown that dose and modality influence outcomes for cognition, back pain, and blood pressure. Two network meta-analyses explored the effects of exercise on depression one among older adults and the other for mental health conditions. Because of the inclusion criteria and search strategies used, these reviews might have been under-powered to explore moderators such as dose and modality κ15 and κ71, respectively. To resolve conflicting findings in existing reviews, we comprehensively searched randomised trials on exercise for depression to ensure our review was adequately powered to identify the optimal dose and modality of exercise. For example, a large overview of reviews found effects on depression to be proportional to intensity, with vigorous exercise appearing to be better, but a later meta-analysis found no such effects. We explored whether recommendations differ based on participants sex, age, and baseline level of depression. Given the challenges presented by behaviour change in people with depression, we also identified autonomy support or behaviour change techniques that might improve the effects of intervention. Behaviour change techniques such as self-monitoring and action planning have been shown to influence the effects of physical activity interventions in adults 18 years and older adults 60 years with differing effectiveness of techniques in different populations. We therefore tested whether any intervention components from the behaviour change technique taxonomy were associated with higher or lower intervention effects. Other meta-analyses found that physical activity interventions work better when they provide people with autonomy eg, choices, invitational language. Autonomy is not well captured in the taxonomy for behaviour change technique. We therefore tested whether effects were stronger in studies that provided more autonomy support to patients. Finally, to understand the mechanism of intervention effects, such as self-confidence, affect, and physical fitness, we collated all studies that conducted formal mediation analyses. Methods.\n"
     ]
    }
   ],
   "source": [
    "chunks = utils.split_text_into_chunks(file_content, tokenizer)\n",
    "print(f\"\\n Num chunks: {len(chunks)}\")\n",
    "chunk_ind = 0\n",
    "print(\"\\n----------\")\n",
    "# print(chunks[chunk_ind])\n",
    "\n",
    "print(\"\\n----------\")\n",
    "chunk_processed = utils.preprocess_text(chunks[chunk_ind])\n",
    "print( chunk_processed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hypothesise',\n",
       " 'findingsfor',\n",
       " 'worldwide',\n",
       " 'programmes',\n",
       " 'ssris',\n",
       " 'zealand',\n",
       " 'favourable',\n",
       " 'ovid',\n",
       " 'prisma',\n",
       " 'personalising',\n",
       " 'controlled',\n",
       " 'baseline',\n",
       " 'metaanalyses-network',\n",
       " 'qigong',\n",
       " 'nuanced',\n",
       " 'meta-analysesthat',\n",
       " 'online',\n",
       " 'behavioural',\n",
       " 'psycinfo',\n",
       " 'practised',\n",
       " 'database',\n",
       " 'eg',\n",
       " 'others',\n",
       " 'κ71',\n",
       " 'sportdiscus',\n",
       " 'κ15',\n",
       " 'httpsosf.ionzw6u',\n",
       " 'metaanalysis',\n",
       " 'et',\n",
       " 'inventory-ii',\n",
       " 'heissel',\n",
       " 'british',\n",
       " 'prisma-nma',\n",
       " 'practise',\n",
       " 'existing',\n",
       " 'medline',\n",
       " 'comorbidities',\n",
       " 'assessmentsfor',\n",
       " 'uk',\n",
       " 'australian',\n",
       " 'keywords',\n",
       " 'cochrane',\n",
       " 'american',\n",
       " 'postpartum',\n",
       " 'embase',\n",
       " 'reuptake',\n",
       " 'randomised',\n",
       " 'australia',\n",
       " 's2',\n",
       " 's3',\n",
       " 'neurobiological',\n",
       " 's0',\n",
       " 'predefined',\n",
       " 'waitlist',\n",
       " 'serotonin']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_non_identified_words(valid_words, file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summarize text check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[379], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarized_text \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_num_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(summarized_text)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo Thinkpad T430\\Documents\\LLM Summarizer\\docs-articles-summarizer\\utils.py:52\u001b[0m, in \u001b[0;36msummarize_text\u001b[1;34m(text, min_length, max_length, prompts, print_num_tokens)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_text\u001b[39m(text, min_length, max_length, prompts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, print_num_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     50\u001b[0m     cleaned_text \u001b[38;5;241m=\u001b[39m preprocess_text(text)  \u001b[38;5;66;03m# Preprocess the text\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     tokenized_no_trunc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     full_length \u001b[38;5;241m=\u001b[39m tokenized_no_trunc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull length without truncation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, full_length)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "summarized_text = utils.summarize_text(chunk_processed, tokenizer, 200, 700, prompts, print_num_tokens=True)\n",
    "print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a total of 218 studies described in 246 reports were included , totalling 495 arms and 14170 participants . the most effective exercise modalities were walking or jogging , yoga , strength training , and dancing . to be eligible for inclusion , studies had to be.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a total of 218 studies described in 246 reports were included , totalling 495 arms and 14170 participants . the most effective exercise modalities were walking or jogging , yoga , strength training , and dancing . to be eligible for inclusion , studies had to be.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_long_text(chunks[chunk_ind], 200, 700, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize whole article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise_depression_2024_au\n",
      "\n",
      "major depressive disorder is a leading cause of disability worldwide . access to treatment for many people with depression is limited . exercise may be an effective complement or alternative to drugs and psychotherapy . findings are presented according to the Preferred Reporting Items for Systematic Reviews. a total of 218 studies described in 246 reports were included , totalling 495 arms and 14170 participants . the most effective exercise modalities were walking or jogging , yoga , strength training , and dancing . to be eligible for inclusion , studies had to be. our review did not uncover clear causal mechanisms , but the trends in the data are useful for generating hypotheses . we. the world health organization recommends physical activity for everyone . many patients may have physical , psychological , or social barriers to participation . effective exercise modalities could be considered as core treatments for depression . but not all patients can access treatment easily ; some interventions are cost-effective . and.\n",
      "Summary saved to exercise_depression_2024_au_summary.txt\n"
     ]
    }
   ],
   "source": [
    "final_summary = summarize_long_text(file_content, 200, 700, prompts)\n",
    "\n",
    "base_filename = re.sub(r\".*/(.*)\\.txt$\", r\"\\1\", curr_file)\n",
    "\n",
    "final_text = f\"{base_filename}\\n\\n{final_summary}\"\n",
    "print(final_text)\n",
    "\n",
    "output_filename = f\"{base_filename}_summary.txt\"\n",
    "\n",
    "# Write the final text to a text file\n",
    "with open(output_filename, \"w\") as text_file:\n",
    "    text_file.write(final_text)\n",
    "\n",
    "print(f\"Summary saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
